"""Create a pandas SQL loader module from user-supplied .sql files.

Workflow
========
1. Drop your SQL files into a directory (for example, ``sql/``). The filename
   (minus ``.sql``) becomes the query key when using ``--directory``.
2. Set ``CONNECTION_STRING`` below with your ODBC details (Netezza, etc.), or
   pass ``--connection-string`` when running this script to bake a default into
   the generated module.
3. Either populate ``QUERY_FILES`` or use ``--directory`` to pick up every
   ``.sql`` file automatically.
4. Run ``python manual_sql_loader.py``. A ready-to-import module (default:
   ``generated_sql_loader.py``) will be written next to your SQL files with
   `pd.read_sql` calls for each query.

No attempt is made to extract SQL from the Excel workbookâ€”this tool simply
packages the SQL you provide.
"""
from __future__ import annotations

import argparse
from pathlib import Path
from typing import Dict, Iterable, Mapping

# ---------------------------------------------------------------------------
# User configuration
# ---------------------------------------------------------------------------

# Populate with your connection string (or pass --connection-string at runtime).
CONNECTION_STRING: str = ""

# Explicit mapping of query name -> SQL file path. Paths are resolved relative
# to this script unless they are absolute. Leave empty and rely on --directory
# if you prefer to scan a folder of .sql files automatically.
QUERY_FILES: Mapping[str, str] = {
    # "submissions": "sql/submissions.sql",
    # "other_query": "sql/other_query.sql",
}

# Destination for the generated loader module (relative to the current working
# directory when the script is run if not absolute).
OUTPUT_PATH: Path = Path("generated_sql_loader.py")

# ---------------------------------------------------------------------------

BASE_DIR = Path(__file__).resolve().parent


def resolve_query_files(query_files: Mapping[str, str]) -> Dict[str, Path]:
    resolved: Dict[str, Path] = {}
    for name, path_text in query_files.items():
        path = Path(path_text)
        if not path.is_absolute():
            path = BASE_DIR / path
        resolved[name] = path
    return resolved


def collect_directory_queries(directory: Path, pattern: str = "*.sql", recursive: bool = False) -> Dict[str, Path]:
    if recursive:
        paths = sorted(directory.rglob(pattern))
    else:
        paths = sorted(directory.glob(pattern))
    queries: Dict[str, Path] = {}
    for path in paths:
        if path.is_file():
            key = path.stem
            if key in queries:
                raise ValueError(f"Duplicate query key detected from directory scan: {key}")
            queries[key] = path
    return queries


def read_sql_file(path: Path) -> str:
    if not path.exists():
        raise FileNotFoundError(f"SQL file not found: {path}")
    return path.read_text(encoding="utf-8")


def build_query_map(args: argparse.Namespace) -> Dict[str, Path]:
    if args.directory:
        directory = args.directory
        if not directory.is_absolute():
            directory = (Path.cwd() / directory).resolve()
        queries = collect_directory_queries(directory, pattern=args.pattern, recursive=args.recursive)
        if args.append_default:
            queries.update(resolve_query_files(QUERY_FILES))
        return queries
    return resolve_query_files(QUERY_FILES)


def parse_args(argv: Iterable[str] | None = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Generate a pandas loader module from SQL files.")
    parser.add_argument(
        "--connection-string",
        dest="connection_string",
        help="ODBC connection string (overrides CONNECTION_STRING constant).",
    )
    parser.add_argument(
        "--directory",
        type=Path,
        help="Directory containing .sql files (filenames become query names).",
    )
    parser.add_argument(
        "--pattern",
        default="*.sql",
        help="Glob pattern when scanning --directory (default: *.sql).",
    )
    parser.add_argument(
        "--recursive",
        action="store_true",
        help="Recurse into subdirectories when using --directory.",
    )
    parser.add_argument(
        "--append-default",
        action="store_true",
        help="When using --directory, also include queries listed in QUERY_FILES.",
    )
    parser.add_argument(
        "--list",
        action="store_true",
        help="List discovered queries without generating code.",
    )
    parser.add_argument(
        "--output",
        type=Path,
        help="Destination .py file for the generated loader (default: generated_sql_loader.py).",
    )
    return parser.parse_args(argv)


def generate_loader_code(queries: Mapping[str, str], connection_string: str) -> str:
    lines: list[str] = []
    lines.append('"""Auto-generated SQL loader generated by manual_sql_loader.py."""')
    lines.append("import pandas as pd")
    lines.append("import pyodbc")
    lines.append("from contextlib import closing")
    lines.append("")
    if connection_string:
        lines.append(f"CONNECTION_STRING = {connection_string!r}")
    else:
        lines.append("CONNECTION_STRING = ''  # TODO: populate with your ODBC connection string")
    lines.append("")
    lines.append("QUERIES = {")
    for name, sql in queries.items():
        lines.append(f"    {name!r}: {sql!r},")
    lines.append("}")
    lines.append("")
    lines.append("def load_data(connection_string: str | None = None, autocommit: bool = True) -> dict:")
    lines.append("    \"\"\"Return a dict mapping query names to pandas DataFrames.\"\"\"")
    lines.append("    conn_str = connection_string or CONNECTION_STRING")
    lines.append("    if not conn_str:")
    lines.append("        raise ValueError('Provide a connection string or set CONNECTION_STRING before calling load_data.')")
    lines.append("    results = {}")
    lines.append("    with closing(pyodbc.connect(conn_str, autocommit=autocommit)) as conn:")
    lines.append("        for name, sql in QUERIES.items():")
    lines.append("            results[name] = pd.read_sql(sql, conn)")
    lines.append("    return results")
    lines.append("")
    lines.append("__all__ = ['QUERIES', 'load_data', 'CONNECTION_STRING']")
    lines.append("")
    return "\n".join(lines)


def main(argv: Iterable[str] | None = None) -> int:
    args = parse_args(argv)
    query_map = build_query_map(args)

    if not query_map:
        print("No SQL queries configured. Add entries to QUERY_FILES or use --directory.")
        return 1

    if args.list:
        print("Queries ready for inclusion:")
        for name, path in sorted(query_map.items()):
            print(f"  {name}: {path}")
        return 0

    statements: Dict[str, str] = {}
    for name, path in query_map.items():
        statements[name] = read_sql_file(path)

    output_path = args.output or OUTPUT_PATH
    if not output_path.is_absolute():
        output_path = Path.cwd() / output_path

    code = generate_loader_code(statements, args.connection_string or CONNECTION_STRING)
    output_path.write_text(code, encoding="utf-8")
    print(f"Generated SQL loader written to {output_path}")
    print(f"Included queries: {', '.join(sorted(statements))}")
    return 0


if __name__ == "__main__":  # pragma: no cover
    raise SystemExit(main())
